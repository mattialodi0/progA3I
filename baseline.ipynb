{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cab7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df691aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "  Loading StormEvents_details-ftp_v1.0_d2016_c20250818.csv...\n",
      "    Shape: (56005, 51)\n",
      "  Loading StormEvents_details-ftp_v1.0_d2017_c20250520.csv...\n",
      "    Shape: (57029, 51)\n",
      "  Loading StormEvents_details-ftp_v1.0_d2018_c20250520.csv...\n",
      "    Shape: (62697, 51)\n",
      "  Loading StormEvents_details-ftp_v1.0_d2019_c20250520.csv...\n",
      "    Shape: (67861, 51)\n",
      "  Loading StormEvents_details-ftp_v1.0_d2020_c20251118.csv...\n",
      "    Shape: (61278, 51)\n",
      "  Loading StormEvents_details-ftp_v1.0_d2021_c20250520.csv...\n",
      "    Shape: (61389, 51)\n",
      "  Loading StormEvents_details-ftp_v1.0_d2022_c20250721.csv...\n",
      "    Shape: (69887, 51)\n",
      "\n",
      "Combined dataset shape: (436146, 51)\n"
     ]
    }
   ],
   "source": [
    "# Define paths to the storm events CSV files\n",
    "data_dir = Path('NCEI_datasets/storm_events')\n",
    "files = [\n",
    "    data_dir / 'StormEvents_details-ftp_v1.0_d2016_c20250818.csv',\n",
    "    data_dir / 'StormEvents_details-ftp_v1.0_d2017_c20250520.csv',\n",
    "    data_dir / 'StormEvents_details-ftp_v1.0_d2018_c20250520.csv',\n",
    "    data_dir / 'StormEvents_details-ftp_v1.0_d2019_c20250520.csv',\n",
    "    data_dir / 'StormEvents_details-ftp_v1.0_d2020_c20251118.csv',\n",
    "    data_dir / 'StormEvents_details-ftp_v1.0_d2021_c20250520.csv',\n",
    "    data_dir / 'StormEvents_details-ftp_v1.0_d2022_c20250721.csv',\n",
    "]\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "df_list = []\n",
    "for file in files:\n",
    "    print(f\"  Loading {file.name}...\")\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"    Shape: {df.shape}\")\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate the datasets\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(f\"\\nCombined dataset shape: {df_storm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5004c52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
       "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
       "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
       "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
       "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
       "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
       "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
       "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
       "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
       "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
       "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
       "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b513f94",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected argument value expression (1192041254.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdf.drop(columns=)\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected argument value expression\n"
     ]
    }
   ],
   "source": [
    "useful_column = [\n",
    "    'CZ_TYPE',\n",
    "    'CZ_FIPS',\n",
    "    'CZ_NAME',\n",
    "    'WFO',\n",
    "    'INJURIES_DIRECT', \n",
    "    'INJURIES_INDIRECT', \n",
    "    'DEATHS_DIRECT',\n",
    "    'DEATHS_INDIRECT', \n",
    "    'DAMAGE_PROPERTY', \n",
    "    'DAMAGE_CROPS',\n",
    "    \n",
    "\n",
    "]\n",
    "df.drop(columns=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40156b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
